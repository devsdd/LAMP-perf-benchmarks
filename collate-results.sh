#!/bin/sh

# script to gather, parse and plot the data generated by the benchmark crons
# Package Dependencies:
# gnuplot
# parallel-ssh
# WARNING: this script is currently very specific to a KVM VPS test setup. Will have to modify to generalize

USER="SSH USERNAME HERE"
IDENTITY_FILE="IDENTITY FILE PATH HERE"

if [ $# -ne 4 ]    # Script invoked with no command-line args?
then
	echo "Usage: $0 -h <hosts_file> -b <backend_disk>"
	echo "where\n<hosts_file> is a text file containing a list of hosts (IP's or resolvable names), one per line"
	exit $E_OPTERROR          # Exit and explain usage.
				  # Usage: scriptname -options
				  # Note: dash (-) necessary
fi  

while getopts ":h:b:" opt
do
	case $opt in
		h)	hosts_file="$OPTARG"
		;;
		b)	backend_disk="$OPTARG"
		;;
		*)
			echo "Invalid options or arguments"
			exit $E_OPTERROR
		;;
	esac
done

# the ubuntu parallel-ssh package has a bug due to which it doesn't support multiple SSH options on the command line;
# set StrictHostKeyChecking="no" in your ssh_config file before running this script
parallel-ssh -t 0 -h $hosts_file -l $USER -O IdentityFile=$IDENTITY_FILE -i "sudo service crond stop"
echo "waiting for 20 min for existing processes to finish"

# apache + php benchmark results
parallel-ssh -p 20 -t 0 -h $hosts_file -l $USER -O IdentityFile=$IDENTITY_FILE -i "./apache-php-results.sh"
test -d php || mkdir php
find php/ -mindepth 1 -maxdepth 1 -type d -exec rm -rf '{}' ';'

test -d apache || mkdir apache
find apache/ -mindepth 1 -maxdepth 1 -type d -exec rm -rf '{}' ';'

parallel-slurp -p 20 -h $hosts_file -l $USER -O IdentityFile=$IDENTITY_FILE -L php/ /home/$USER/php-bench.csv php-bench-individual.csv
cat php/*/php-bench-individual.csv > php/php-bench-$backend_disk.csv
gnuplot -e "infile='php/php-bench-$backend_disk.csv'; outfile='php/php-bench-$backend_disk.png' ; disk='$backend_disk' ; linecount='`wc -l php/php-bench-$backend_disk.csv`'" php.gp

parallel-slurp -p 20 -h $hosts_file -l $USER -O IdentityFile=$IDENTITY_FILE -L apache/ /home/$USER/apache-bench.csv apache-bench-individual.csv
cat apache/*/apache-bench-individual.csv > apache/apache-bench-$backend_disk.csv
gnuplot -e "infile='apache/apache-bench-$backend_disk.csv'; outfile='apache/apache-bench-$backend_disk.png' ; disk='$backend_disk' ; linecount='`wc -l apache/apache-bench-$backend_disk.csv`'" apache.gp

# MySQL results
parallel-ssh -p 20 -t 0 -h $hosts_file -l $USER -O IdentityFile=$IDENTITY_FILE -i "./mysql-results.sh"
test -d mysql || mkdir mysql
find mysql/ -mindepth 1 -maxdepth 1 -type d -exec rm -rf '{}' ';'

parallel-slurp -p 20 -r -h $hosts_file -l $USER -O IdentityFile=$IDENTITY_FILE -L mysql/ /home/$USER/mysql mysql
cat mysql/*/mysql/alter-table.csv > mysql/alter-table-$backend_disk.csv
cat mysql/*/mysql/big-tables.csv > mysql/big-tables-$backend_disk.csv
cat mysql/*/mysql/create.csv > mysql/create-$backend_disk.csv
cat mysql/*/mysql/insert.csv > mysql/insert-$backend_disk.csv
cat mysql/*/mysql/select.csv > mysql/select-$backend_disk.csv

gnuplot -e "infile='mysql/alter-table-$backend_disk.csv'; outfile='mysql/alter-table-$backend_disk.png' ; disk='$backend_disk' ; linecount='`wc -l mysql/alter-table-$backend_disk.csv`' ; operation='Alter Table'" mysql.gp
gnuplot -e "infile='mysql/big-tables-$backend_disk.csv'; outfile='mysql/big-tables-$backend_disk.png' ; disk='$backend_disk' ; linecount='`wc -l mysql/big-tables-$backend_disk.csv`' ; operation='Big Tables'" mysql.gp
gnuplot -e "infile='mysql/create-$backend_disk.csv'; outfile='mysql/create-$backend_disk.png' ; disk='$backend_disk' ; linecount='`wc -l mysql/create-$backend_disk.csv`' ; operation='Create'" mysql.gp
gnuplot -e "infile='mysql/insert-$backend_disk.csv'; outfile='mysql/insert-$backend_disk.png' ; disk='$backend_disk' ; linecount='`wc -l mysql/insert-$backend_disk.csv`' ; operation='Insert'" mysql.gp
gnuplot -e "infile='mysql/select-$backend_disk.csv'; outfile='mysql/select-$backend_disk.png' ; disk='$backend_disk' ; linecount='`wc -l mysql/select-$backend_disk.csv`' ; operation='Select'" mysql.gp

# fio results
parallel-ssh -p 20 -t 0 -h $hosts_file -l $USER -O IdentityFile=$IDENTITY_FILE -i "./fio-results.sh"
test -d fio || mkdir fio
find fio/ -mindepth 1 -maxdepth 1 -type d -exec rm -rf '{}' ';'

parallel-slurp -r -h $hosts_file -l $USER -O IdentityFile=$IDENTITY_FILE -L fio/ /home/$USER/fio fio
cat fio/*/fio/read_clat.csv > fio/read_clat-$backend_disk.csv
cat fio/*/fio/read_iops.csv > fio/read_iops-$backend_disk.csv
cat fio/*/fio/write_clat.csv > fio/write_clat-$backend_disk.csv
cat fio/*/fio/write_iops.csv > fio/write_iops-$backend_disk.csv

max=`sort -rn fio/read_clat-$backend_disk.csv | head -1 | cut -d '.' -f 1`
header=`echo $max \* 0.1 | bc`
ylimit=`echo $max + $header | bc | cut -d '.' -f 1`
gnuplot -e "infile='fio/read_clat-$backend_disk.csv' ; outfile='fio/read_clat-$backend_disk.png' ;  disk='$backend_disk' ; linecount='`wc -l fio/read_clat-$backend_disk.csv  | awk '{print $1}'`' ; operation='read' ; ylimit='$ylimit' " fio-clat.gp

max=`sort -rn fio/write_clat-$backend_disk.csv | head -1 | cut -d '.' -f 1`
header=`echo $max \* 0.1 | bc`
ylimit=`echo $max + $header | bc | cut -d '.' -f 1`
gnuplot -e "infile='fio/write_clat-$backend_disk.csv' ; outfile='fio/write_clat-$backend_disk.png' ;  disk='$backend_disk' ; linecount='`wc -l fio/write_clat-$backend_disk.csv  | awk '{print $1}'`' ; operation='write' ; ylimit='$ylimit' " fio-clat.gp

max=`sort -rn fio/read_iops-$backend_disk.csv | head -1 | cut -d '.' -f 1`
header=`echo $max \* 0.1 | bc`
ylimit=`echo $max + $header | bc | cut -d '.' -f 1`
gnuplot -e "infile='fio/read_iops-$backend_disk.csv' ; outfile='fio/read_iops-$backend_disk.png' ;  disk='$backend_disk' ; linecount='`wc -l fio/read_iops-$backend_disk.csv  | awk '{print $1}'`' ; operation='read' ; ylimit='$ylimit' " fio-iops.gp

max=`sort -rn fio/write_iops-$backend_disk.csv | head -1 | cut -d '.' -f 1`
header=`echo $max \* 0.1 | bc`
ylimit=`echo $max + $header | bc | cut -d '.' -f 1`
gnuplot -e "infile='fio/write_iops-$backend_disk.csv' ; outfile='fio/write_iops-$backend_disk.png' ;  disk='$backend_disk' ; linecount='`wc -l fio/write_iops-$backend_disk.csv  | awk '{print $1}'`' ; operation='write' ; ylimit='$ylimit' " fio-iops.gp
